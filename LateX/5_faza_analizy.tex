\section{Faza analizy}
\subsection{Wstęp}

\indent Block

\clearpage

\subsection{Cele i założenia}

\subsection{Podstawa teoretyczna}
\begin{enumerate}
    
    \item {\bf Model językowy} - Model językowy w dziedzinie informatyki i sztucznej inteligencji to system komputerowy zaprojektowany do rozumienia, interpretowania i generowania ludzkiego języka naturalnego. Opiera się on na algorytmach uczenia maszynowego, głównie uczenia głębokiego, które uczą się struktury, semantyki i kontekstu języka przez analizę i przetwarzanie ogromnych zbiorów tekstów.

    Takie modele składają się z wielowarstwowych sieci neuronowych, z których każda warstwa przetwarza różne aspekty języka, od rozpoznawania słów po interpretację znaczeń. Centralnym elementem jest algorytm 'transformer', który efektywnie przetwarza długie sekwencje tekstu, zachowując kontekst i znaczenie.
    
    Modele językowe są trenowane na dużych zbiorach tekstowych, zawierających różnorodne formy języka. Proces treningu polega na dostosowywaniu parametrów sieci neuronowej, aby jak najlepiej odwzorować naturalne użycie języka. W wyniku tego treningu, modele te są zdolne do tworzenia nowych, koherentnych wypowiedzi, reagowania na zapytania i analizy języka na wysokim poziomie.
    \\
    \item {\bf Model GPT} - Modele GPT (Generative Pre-trained Transformer) to rodzaj zaawansowanych modeli językowych opracowanych przez firmę OpenAI wykorzystujących architekturę transformer w dziedzinie sztucznej inteligencji. Zostały one zaprojektowane do generowania tekstu, interpretacji języka naturalnego oraz wykonywania różnorodnych zadań związanych z przetwarzaniem języka. Ich główną cechą jest zdolność do generowania spójnego i kontekstualnie odpowiedniego tekstu na podstawie dostarczonych informacji wejściowych.

    GPT opiera się na technice uczenia głębokiego, gdzie modele są trenowane na ogromnych zbiorach tekstowych w celu nauki struktury języka, jego semantyki oraz różnorodnych kontekstów. Model GPT, wykorzystując architekturę transformer, skutecznie przetwarza i analizuje długie sekwencje tekstu, co pozwala na zachowanie złożonego kontekstu i generowanie koherentnych odpowiedzi.
    
    Kluczowym aspektem modeli GPT jest ich pre-trening, czyli wstępne szkolenie na szerokiej gamie danych tekstowych. Dzięki temu modele te rozwijają ogólną zdolność do rozumienia i generowania języka, którą następnie można dostosować do konkretnych zastosowań (tzw. fine-tuning).
    
    Modele GPT są wykorzystywane w różnych aplikacjach, od automatycznego generowania tekstu, przez tworzenie odpowiedzi w systemach dialogowych, po zaawansowane analizy językowe. Ich zdolność do generowania naturalnego, spójnego i kontekstowo odpowiedniego języka sprawia, że znajdują one zastosowanie w wielu dziedzinach, w tym w rozrywce, edukacji oraz biznesie.
    \\
     
 \end{enumerate}

\clearpage

\subsection{Prompt engineering}

\subsubsection{Opis modeli językowych}

\begin{enumerate}
 \item {\bf ChatGPT} - to specjalistyczna wersja modelu językowego opracowana przez OpenAI, zaprojektowana głównie do prowadzenia konwersacji w formie tekstowej. Jest to aplikacja modelu GPT (Generative Pre-trained Transformer) skoncentrowana na interakcjach dialogowych, zdolna do generowania naturalnie brzmiących, koherentnych i kontekstualnie adekwatnych odpowiedzi w czasie rzeczywistym.

    Podstawą działania ChatGPT jest zaawansowany model językowy oparty na architekturze transformer, który został wytrenowany na ogromnych zbiorach danych tekstowych, w tym na dialogach i rozmowach. Dzięki temu ChatGPT wykazuje zdolność do zrozumienia zapytań w kontekście konwersacji i generowania płynnych, spójnych odpowiedzi.
    
    ChatGPT wyróżnia się zdolnością do utrzymania spójnego kontekstu rozmowy, co pozwala na prowadzenie dłuższych interakcji, które wydają się naturalne i są bardziej angażujące dla użytkownika. Może on odpowiadać na pytania, prowadzić dyskusje na różne tematy, oferować pomoc lub informacje, a także angażować się w bardziej twórcze zadania, takie jak pisanie opowiadań czy wierszy.
    
    Model ten jest często wykorzystywany w aplikacjach do obsługi klienta, asystentach cyfrowych, edukacji, a także jako narzędzie do interakcji i angażowania użytkowników na platformach internetowych. Zdolność ChatGPT do naturalnej interakcji językowej sprawia, że znajduje on zastosowanie w różnorodnych środowiskach, gdzie istotna jest zdolność do prowadzenia płynnej, ludzko brzmiącej konwersacji.
    \\
    \item {\bf Gemini} - to duży model językowy (LLM), który jest szkolony na ogromnym zbiorze danych tekstu i kodu. LLM-y są w stanie generować tekst, tłumaczyć języki, pisać różnego rodzaju kreatywne treści i odpowiadać na pytania w sposób informacyjny.
    \\

\end{enumerate}

\subsubsection{Analiza przypdaków użycia modeli językowych}

Rozwój modeli językowych, szczególnie za sprawą zaawansowanych technologii opartych na sztucznej inteligencji, wprowadził nowe możliwości w dziedzinie przetwarzania języka naturalnego. Jednym z kluczowych obszarów wykorzystania tych modeli jest prompt engineering, czyli kształtowanie i dostosowywanie zapytań (promptów) w celu uzyskania pożądanych odpowiedzi od modeli językowych. Niniejszy rozdział skupia się na analizie konkretnych przypadków użycia modeli językowych w kontekście prompt engineeringu.

Przed przystąpieniem do analizy przypadków użycia istotne jest określenie modeli językowych, które będą poddane ocenie. W ramach niniejszej pracy magisterskiej skupimy się na modelach opartych na architekturze GPT (Generative Pre-trained Transformer), a w szczególności na, GPT-3.5,GPT-4, oraz Bard. Wybór tych modeli wynika z ich doskonałej zdolności do zrozumienia kontekstu, elastyczności w generowaniu tekstów oraz szerokiej gamy zastosowań w dziedzinie języka naturalnego.
 
Analiza przypadków użycia rozpocznie się od szczegółowego zrozumienia procesu prompt engineeringu. Proces ten obejmuje identyfikację celu zapytania, dostosowanie struktury promptu, a także optymalizację parametrów modelu w celu uzyskania precyzyjnych i zadowalających wyników. Przeanalizujemy różne strategie prompt engineeringu, w tym zmiany w sformułowaniu pytań, manipulacje długością promptu oraz eksperymenty z parametrami kontekstowymi.

\subsubsection{Projektowanie promptów}

\noindent\textbf{Wprowadzenie}

Projektowanie prompt'ów jest kluczowym aspektem w tworzeniu efektywnych interakcji z modelami językowymi. Precyzyjne i dobrze sformułowane pytania mają decydujący wpływ na jakość generowanych odpowiedzi. W tym rozdziale skoncentrujemy się na procesie projektowania prompt'ów, w tym na strategiach wyboru słów kluczowych, formatowaniu zapytań oraz eksperymentach z różnymi rodzajami promptów.
\\

\noindent\textbf{Analiza celu naszego prompta}

Każdy prompt, musi zostac tak zaprojektowany aby spełniał wymagania techniczne aplikacji.
Aplikacja jest podzielona na wiele etapów gdzie użytkownik otrzymuje specjalnie przygotowane odpowiedzi w zależności od opcji, które wybierze.
\\

\noindent\textbf{Wybór Słów Kluczowych}

Pierwszym etapem projektowania prompt'ów jest staranne dobranie słów kluczowych. Te słowa stanowią istotny element, który kieruje modelem językowym w odpowiednim kierunku. Analiza semantyczna i kontekstualna danego zadania jest kluczowa w identyfikacji słów, które mają kluczowe znaczenie dla uzyskania precyzyjnych odpowiedzi. W tym kontekście eksperymenty z różnymi formułowaniami pytań mogą prowadzić do odkrycia najbardziej efektywnych kombinacji słów kluczowych.
\\

\noindent\textbf{Struktura Prompt'ów}

Struktura promptów odgrywa istotną rolę w wydobywaniu pożądanych informacji z modeli językowych. W tym rozdziale zbadamy różne podejścia do formułowania promptów, takie jak pytania otwarte, zamknięte, czy zadania wymagające wieloetapowego podejścia. Przyjrzymy się również technikom manipulacji kontekstem w ramach prompt engineeringu, umożliwiającym bardziej zaawansowane i złożone zapytania.

\subsubsection{Prompt security}

{\bf Czym jest bezpieczeństwo promptów?}

\noindent Bezpieczeństwo promptów dotyczy ochrony przed złośliwym wykorzystaniem duzych modeli językowych (LLM) poprzez manipulowanie promptami, czyli wejściami dostarczanymi modelowi. Ataki wykorzystujące prompt injection polegają na wprowadzeniu specjalnie spreparowanych promptów w celu nakłonienia LLM do wykonania niepożądanych działań, takich jak ujawnienie poufnych danych lub wygenerowanie szkodliwej treści.
\\

\noindent {\bf Rodzaje ataków na prompt security:}

\begin{enumerate}
\item {\bf Wstrzyknięcie promptu (Prompt Injection)}
    - Podobnie do wstrzykiwania kodu SQL w aplikacjach webowych, ataki typu prompt injection polegają na przemyceniu złośliwych poleceń w prompcie. Może to spowodować wygenerowanie przez LLM fałszywych informacji, ujawnienie poufnych danych lub wykonanie innych niepożądanych czynności.
\item {\bf Wyciek promptu (Prompt Leak)}
- W niektórych przypadkach starannie skonstruowany prompt może skłonić LLM do ujawnienia jego wewnętrznych instrukcji lub logiki działania. Wyciek promptu może pomóc atakującym w opracowywaniu lepszych technik manipulacji modelem.
\end{enumerate}

{\bf Znaczenie bezpieczeństwa promptów}

\noindent Bezpieczeństwo promptów jest kluczowe dla zapewnienia odpowiedzialnego rozwoju i wdrażania technologii GenAI. Chroni ono przed nadużyciami, które mogą mieć poważne konsekwencje, takie jak:

\begin{enumerate}
    \item {\bf Utrata danych poufnych}
    - Wstrzyknięcie promptu może zmusić LLM do ujawnienia poufnych informacji, takich jak dane finansowe lub dane osobowe.
    \item {\bf Dezinformacja i propaganda}
    - Ataki mogą być wykorzystywane do generowania fałszywych wiadomości lub propagandy, która może wpływać na opinię publiczną.
    \item {\bf Spam i phishing}
    - Generatywne AI mogą być wykorzystywane do tworzenia masowych wiadomości spamowych lub realistycznych wiadomości phishingowych służących wyłudzaniu informacji.
\end{enumerate}


{\bf Rozwiązania bezpieczeństwa promptów}

\noindent Firmy zajmujące się bezpieczeństwem cybernetycznym opracowują narzędzia i techniki wykrywania i zapobiegania atakom na prompt security. Niektóre z rozwiązań obejmują:

\begin{enumerate}
    \item {\bf Analizę i monitorowanie promptów} - Wykrywanie podejrzanych wzorców w promptach wprowadzanych do LLM.
    \item {\bf Weryfikację danych wyjściowych} - Sprawdzanie, czy wygenerowane przez LLM dane są zgodne z oczekiwaniami i nie zawierają szkodliwych informacji.
    \item {\bf Szkolenie LLM w zakresie bezpieczeństwa} - Opracowywanie modeli odpornych na manipulacje poprzez odpowiednie ich szkolenie.
\end{enumerate}

{\bf Wnioski}

\noindent Bezpieczeństwo promptów to ważny, ale często pomijany aspekt rozwoju i wdrażania generatywnej sztucznej inteligencji. Wraz z ciągłym rozwojem technologii GenAI, konieczne jest opracowanie solidnych mechanizmów bezpieczeństwa w celu ochrony przed potencjalnymi zagrożeniami. Rozwiązania te zapewnią, że GenAI będzie wykorzystywana w sposób odpowiedzialny i przyniesie korzyści społeczeństwu.


\subsubsection{Fine-tuning}
Jest to modyfikowanie istniejących modeli językowych w celu dostosowania ich do konkretnego zadania lub zbioru danych, odgrywa kluczową rolę w dziedzinie uczenia maszynowego i przetwarzania języka naturalnego. Proces ten polega na dalszym trenowaniu modeli na specyficznych danych lub zadaniach, co pozwala na poprawę ich wydajności i skuteczności w konkretnych zastosowaniach. Fine-tuning modeli LLM może być stosowany do różnorodnych zadań, takich jak tłumaczenie maszynowe, generowanie tekstu, analiza sentymentu czy wykrywanie fraz kluczowych. W ten sposób możliwe jest dostosowanie ogólnych modeli językowych do specyficznych potrzeb użytkowników i zastosowań, co przyczynia się do poprawy jakości rezultatów oraz dostosowania modeli do konkretnego kontekstu biznesowego lub naukowego.

\subsubsection{Large Language Models}
Duże modele językowe (LLM) to zaawansowane algorytmy sztucznej inteligencji, które wykorzystują techniki głębokiego uczenia się i obszerne zbiory danych do generowania, podsumowywania i przewidywania nowych treści w języku naturalnym. Modele te, takie jak LLM oparte na transformatorach, są zaprojektowane tak, aby rozumieć relacje między słowami i frazami, umożliwiając im równoległe przetwarzanie całych sekwencji tekstu. Modele LLM są szkolone na ogromnych ilościach danych, zazwyczaj z miliardami parametrów, co pozwala im na dostarczanie dokładnych i szybkich odpowiedzi w różnych dziedzinach. LLM mają wiele zalet dla organizacji i użytkowników, w tym rozszerzalność, zdolność adaptacji, elastyczność, wysoką wydajność, dokładność i łatwość szkolenia. Można je dostosować do konkretnych przypadków użycia, wykonywać różne zadania i generować odpowiedzi z niskim opóźnieniem. Jednak LLM wiążą się również z wyzwaniami, takimi jak wysokie koszty rozwoju i operacyjne, potencjalna stronniczość danych szkoleniowych, brak możliwości wyjaśnienia wyników, ryzyko halucynacji (dostarczanie niedokładnych odpowiedzi) oraz złożoność ze względu na dużą liczbę parametrów. Modele te mają szeroki zakres zastosowań w dziedzinach takich jak technologia, opieka zdrowotna, obsługa klienta, marketing, prawo, bankowość i wiele innych. Mogą pomagać w zadaniach takich jak copywriting, odpowiadanie na pytania z bazy wiedzy, transformacja miejsca pracy i konwersacyjna sztuczna inteligencja. LLM zmieniają sposób, w jaki technologia wchodzi w interakcję z użytkownikami i są uważane za kluczowy element nowoczesnego krajobrazu cyfrowego, rewolucjonizując i ulepszając środowisko pracy.

\subsubsection{Ranking Modeli???}

\subsubsection{Etyka}
Etyczne wykorzystanie modeli językowych oraz sztucznej inteligencji jest kluczowe w dzisiejszym świecie technologicznym. W kontekście rozwijających się Large Language Models (LLMs) i sztucznej inteligencji, istnieje konieczność uwzględnienia kwestii etycznych, moralnych oraz odpowiedzialnego podejścia do ich zastosowań. Modeli językowych, takich jak GPT-3.5 czy inne zaawansowane systemy AI, mogą generować treści, odpowiadać na pytania, tłumaczyć języki, czy nawet projektować. Jednakże, istnieje ryzyko, że te modele mogą przekazywać błędne informacje, szerzyć dezinformację, lub być źródłem treści szkodliwych. Dlatego ważne jest, aby organizacje i twórcy tych modeli dbali o uczciwość, transparentność, oraz odpowiedzialność za generowane treści. W kontekście etyki, istotne jest również zapewnienie, że modele językowe nie promują dyskryminacji, uprzedzeń, czy szkodliwych treści. Konieczne jest monitorowanie i regulacja sposobu, w jaki te modele są używane, aby zapewnić, że służą dobrobytowi społeczeństwa i nie naruszają praw człowieka. Ważne jest również, aby modele językowe były rozwijane z poszanowaniem prywatności danych, zapewnieniem bezpieczeństwa informacji oraz zgodności z przepisami dotyczącymi ochrony danych osobowych. Odpowiedzialne podejście do tworzenia i wykorzystywania modeli językowych jest kluczowe dla budowania zaufania społecznego do sztucznej inteligencji i technologii opartych na AI.
\clearpage

\subsection{Platformy chmurowe}
Platformy chmurowe to zaawansowane systemy, które umożliwiają firmom i organizacjom dostęp do zasobów obliczeniowych przez Internet, bez konieczności posiadania i zarządzania własną infrastrukturą IT. Oto kilka kluczowych informacji na temat platform chmurowych:

Definicja i Działanie

Platforma chmurowa to system operacyjny i sprzęt serwerów w centrum danych, skonfigurowany do świadczenia usług obliczeniowych dla klientów. Umożliwia ona firmom wynajmowanie dostępu do zasobów obliczeniowych, takich jak serwery, bazy danych, magazyny danych, analityka, sieci, oprogramowanie i inteligencja, na zasadzie płatności za użycie.

Rodzaje Platform Chmurowych

1. Chmura Publiczna: Usługi świadczone przez zewnętrznych dostawców, dostępne dla wielu klientów przez Internet. Przykłady to Amazon Web Services (AWS), Google Cloud Platform, Microsoft Azure, Alibaba Cloud i IBM Cloud.
2. Chmura Prywatna: Dedykowana dla jednej organizacji, może być zarządzana wewnętrznie lub przez zewnętrznego dostawcę. Oferuje większą kontrolę nad zasobami i bezpieczeństwem.
3. Chmura Hybrydowa: Kombinacja chmury publicznej i prywatnej, umożliwiająca przenoszenie danych i aplikacji między nimi, co zapewnia większą elastyczność i optymalizację infrastruktury.

Korzyści z Używania Platform Chmurowych

- Elastyczność: Możliwość szybkiego skalowania zasobów w górę lub w dół w zależności od potrzeb biznesowych, co pozwala unikać ryzyka nadmiernego lub niedostatecznego przydziału zasobów.
- Redukcja Kosztów: Eliminacja kosztów kapitałowych związanych z budową i utrzymaniem własnych centrów danych oraz płatność tylko za faktycznie używane zasoby.
- Wydajność: Dostęp do dużej mocy obliczeniowej i magazynowej na żądanie, co pozwala unikać wąskich gardeł i zapewnia lepszą wydajność aplikacji.
- Szybkość Wdrożenia: Możliwość szybkiego wdrażania technologii na całym świecie, co skraca czas wprowadzenia produktów na rynek.
- Zwiększona Produktywność: Zespoły IT są zwolnione z zarządzania, utrzymania i aktualizacji sprzętu i oprogramowania na miejscu, co pozwala im skupić się na bardziej strategicznych zadaniach.
- Bezpieczeństwo: Dostawcy chmurowi inwestują znaczne środki w technologie zabezpieczające, co często zapewnia wyższy poziom bezpieczeństwa niż w przypadku własnych centrów danych.
- Niezawodność: Platformy chmurowe są bardziej odporne dzięki rozproszonej infrastrukturze, co zapewnia szybsze odzyskiwanie danych po awariach.

Platformy chmurowe odgrywają kluczową rolę w nowoczesnych strategiach IT, umożliwiając firmom szybkie i efektywne skalowanie swoich operacji oraz wprowadzanie innowacji.
\subsubsection{Opis platform}
Platformy chmurowe to zintegrowane zestawy technologii umożliwiające użytkownikom zdalne korzystanie z szerokiej gamy zasobów komputerowych przez Internet. Te cyfrowe ekosystemy oferują skalowalne rozwiązania IT, takie jak serwery, pamięć, bazy danych oraz oprogramowanie, wszystko dostępne jako usługa. Główne kategorie tych usług to: Infrastructure as a Service (IaaS), Platform as a Service (PaaS) oraz Software as a Service (SaaS).

Korzystanie z platform chmurowych przynosi wiele korzyści. Elastyczność i skalowalność pozwalają na szybkie dostosowywanie zasobów do aktualnych potrzeb, bez konieczności inwestycji w drogie sprzęty i infrastrukturę. Oszczędności kosztów wynikają z modelu opłat "pay as you go", co oznacza, że płaci się tylko za te zasoby, które są faktycznie wykorzystywane. Bezpieczeństwo danych jest również kluczowym aspektem, z zaawansowanymi rozwiązaniami chroniącymi przed utratą danych i cyberatakami.
\subsubsection{Wybór - Plaforma Microsoft Azure}
\clearpage
Platfroma Azure została wybrana do naszego projektu ze względu na to,że nasz zespół miał już doświadczenie zarówno prywatne jak i komercyjne w tej technologi. Kolejnym atutem rozwiązania firmy z Redmond, jest bogata oferta serwisów oraz technologii potrzebnych do zbudowania do aplikacji opartej o architekturę mikroserwisów.
W tym kontekście, Azure okazuje się być idealną platformą do rozwijania mikroserwisów dzięki usługom takim jak Azure Kubernetes Service, który upraszcza zarządzanie kontenerami, oraz Azure Container Instances. Platforma oferuje również integracje z narzędziami deweloperskimi oraz CI/CD.

\subsection{Wymagania funkcjonalne}

\subsubsection{Opis funkcjonalności systemu}

\subsubsection{Diagram przypadków użycia}

\subsubsection{Scenariusze przypadków użycia}

\subsubsection{Sposób przechowywania danych}
Dane użytkowników są przechowywane w bazie danych PostgreSQL, co zapewnia efektywne zarządzanie dużymi zbiorami danych oraz wysoki poziom bezpieczeństwa. PostgreSQL, jako zaawansowany system zarządzania relacyjnymi bazami danych, oferuje szerokie możliwości skalowania i optymalizacji, co jest kluczowe przy obsłudze danych wrażliwych i osobowych.

\subsubsection{Diagramy}
\clearpage

\subsection{Wymagania niefunkcjonalne}
\begin{itemize}
    \item[*] W przypadku gdy użytkownik korzysta z komputera stacjonarnego lub urządzenia mobilnego aplikacja powinna działać na jednej z powyższych przeglądarek: Google Chrome(wersja 95 i wyżej), Opera GX. 
    \item[*] Aplikacja powinna poprawnie działać na serwerze aplikacyjnym z następującymi parametrami: procesor 8 rdzeni, 16 gb DDR4 pamięci operacyjnej RAM, przestrzeń dyskowa 128gb (SSD) na pliki, indeksy i skany. Rekomendowanym systemem operacyjnym jest Windows Server 2012 R2 lub nowszy.
\end{itemize}
\clearpage

\subsection{Opis prototypów}
Prototypy opracowane na etapie planowania całej aplikacji okazały się niezwykle pomocne w ustaleniu funkcjonalności oraz ogólnego zarysu aplikacji. Jednakże, po dokładnej analizie trendów dotyczących UX/UI oraz tematyki aplikacji, konieczne było wykonanie nowego aspektu wizualnego. Zmieniono kolorystykę oraz doprecyzowano wygląd poszczególnych komponentów, aby spełnić wymagania standardów UX/UI oraz zapewnić użytkownikom maksymalny komfort podczas korzystania z aplikacji. Ważnym celem było stworzenie projektu przyjaznego i intuicyjnego, a także spełnienie wymogów dotyczących dostępności. Wszystkie te aspekty zostały uwzględnione podczas projektowania i implementacji aplikacji.

\begin{figure}[h]
    \centering
    \includegraphics[width=1\textwidth]{Obrazy/prototypy/logowanie.png}
    \caption{Prototyp ekranu logowania}
    \label{fig:my_label}
\end{figure}

\begin{figure}[h]
    \centering
    \includegraphics[width=1\textwidth]{Obrazy/prototypy/personalizacja_konta.png}
    \caption{Prototyp ekranu personalizacji konta}
    \label{fig:my_label}
\end{figure}

\begin{figure}[h]
    \centering
    \includegraphics[width=1\textwidth]{Obrazy/prototypy/strona_startowa.png}
    \caption{Prototyp strony startowej}
    \label{fig:my_label}
\end{figure}

\begin{figure}[h]
    \centering
    \includegraphics[width=1\textwidth]{Obrazy/prototypy/panel_zadania.png}
    \caption{Prototyp panelu zadania}
    \label{fig:my_label}
\end{figure}

\begin{figure}[h]
    \centering
    \includegraphics[width=1\textwidth]{Obrazy/prototypy/kalendarz.png}
    \caption{Prototyp kalendarza}
    \label{fig:my_label}
\end{figure}

\begin{figure}[h]
    \centering
    \includegraphics[width=1\textwidth]{Obrazy/prototypy/profil_uzytkownika.png}
    \caption{Prototyp profilu użytkownika}
    \label{fig:my_label}
\end{figure}

\clearpage