\section{Faza analizy}
\subsection{Wstęp}

W dobie dynamicznego rozwoju technologii informatycznych, sztuczna inteligencja (AI) oraz uczenie maszynowe (ML) odgrywają coraz większą rolę w różnorodnych dziedzinach życia. Jednym z najnowszych osiągnięć\linebreak w tej dziedzinie są modele językowe dużej skali (LLM), które potrafią generować tekst na wysokim poziomie zrozumienia i spójności. Modele te, takie jak Chat-GPT, LLama czy Zephyr, znajdują szerokie zastosowanie w wielu branżach, od tworzenia treści po automatyzację obsługi klienta.

Projekt ma na celu stworzenie aplikacji webowej, która wykorzystując modele LLM, będzie w stanie generować plany działania prowadzące do osiągnięcia określonych celów, takich jak np. przebiegnięcie maratonu czy nauka programowania. Aplikacja ma wspierać użytkowników w realizacji tych celów poprzez dostarczanie zadań i harmonogramów działania. W ramach pracy porównane zostaną różne modele LLM pod kątem jakości generowanych planów oraz ich efektywności.

Aplikacja została zbudowana w oparciu o nowoczesne technologie frontendowe i backendowe. Interfejs użytkownika został zaprojektowany\linebreak z wykorzystaniem biblioteki React, natomiast backend aplikacji jest oparty na języku C\# oraz frameworku ASP.NET Core. Kluczowym elementem projektu będzie również implementacja architektury mikroserwisowej w chmurze Azure, co zapewni skalowalność i niezawodność systemu.

Niniejsza praca dostarczy wartościowych informacji i praktycznych rozwiązań w zakresie wykorzystania modeli LLM do wspomagania realizacji celów użytkowników, a także przyczyni się do dalszego rozwoju aplikacji webowych wykorzystujących nowoczesne technologie informatyczne.

\clearpage

\subsection{Cele i założenia}

\noindent{\bf Cel główny:}

Zaprojektowanie i implementacja aplikacji webowej, która wykorzystując modele językowe dużej skali (LLM), będzie w stanie generować plany działania prowadzące do osiągnięcia określonych przez użytkownika celów, takich jak przebiegnięcie maratonu czy nauka programowania. Aplikacja ma wspierać, korzystające z niej osoby w realizacji tych celów poprzez dostarczanie zadań i harmonogramów w określonym przedziale czasowym, który najbardziej odpowiada użytkownikowi.
\\

\noindent{\bf Cele szczegółowe: }
\begin{enumerate}
    \item {\bf Analiza i porównanie różnych modeli LLM:}
        \begin{itemize}
            \item[*] Przeprowadzenie badań nad dostępnymi modelami LLM, takimi jak Chat GPT, LLAMA, Zephyr Stable, i ich zdolnościami do generowania zadań.
            \item[*] Porównanie wybranych modeli pod kątem jakości generowanych planów, efektywności oraz zasobów obliczeniowych.
       \end{itemize}
    
    \item {\bf Projekt i implementacja aplikacji webowej:}
        \begin{itemize}
            \item[*] Stworzenie interfejsu użytkownika za pomocą React, umożliwiającego łatwą interakcję z aplikacją.
            \item[*] Implementacja backendu w języku C\# z wykorzystaniem frameworku ASP.NET Core, który będzie obsługiwał logikę biznesową oraz komunikację z modelami LLM.
       \end{itemize}
    
    \item {\bf Integracja z modelami LLM:}
        \begin{itemize}
            \item[*] Zintegrowanie wybranych modeli LLM z aplikacją w sposób umożliwiający dynamiczne generowanie planów i zadań.
            \item[*] Zapewnienie mechanizmów optymalizacji i skalowalności w celu obsługi wielu użytkowników jednocześnie.
       \end{itemize}
    
    \item {\bf Budowa architektury mikroserwisowej w chmurze Azure:}
        \begin{itemize}
            \item[*] Zdefiniowanie mikroserwisów odpowiadających za różne funkcjonalności aplikacji (np. zarządzanie użytkownikami, komunikacja z LLM, tworzenie harmonogramów zadań).
            \item[*] Implementacja i wdrożenie mikroserwisów w środowisku chmurowym Azure z użyciem takich technologii jak Docker, Kubernetes, Azure Container Instances, Azure KeyVault, Terraform, Github Actions.
       \end{itemize}
    
    \item {\bf Testowanie i walidacja:}
        \begin{itemize}
            \item[*] Przeprowadzenie testów funkcjonalnych i wydajnościowych aplikacji oraz poszczególnych mikroserwisów.
       \end{itemize}
    
    \item {\bf Dokumentacja i raportowanie wyników:}
        \begin{itemize}
            \item[*] Opracowanie pełnej dokumentacji technicznej projektu, obejmującej zarówno kod źródłowy, jak i szczegółowe opisy architektury i integracji.
            \item[*] Sporządzenie raportu z wyników porównania modeli LLM oraz.
       \end{itemize}

\end{enumerate}

\noindent{\bf Założenia }
\begin{enumerate}
    \item {\bf Skalowalność:}
        \begin{itemize}
            \item[*] Aplikacja musi być skalowalna i zdolna do obsługi dużej liczby jednoczesnych użytkowników bez znacznej utraty wydajności.
       \end{itemize}
    
    \item {\bf Interaktywność i intuicyjność:}
        \begin{itemize}
            \item[*] Interfejs użytkownika musi być prosty, intuicyjny i przyjazny, aby umożliwić łatwą interakcję z aplikacją nawet mniej zaawansowanym technicznie użytkownikom.
       \end{itemize}
    
    \item {\bf Bezpieczeństwo danych:}
        \begin{itemize}
            \item[*] Wszelkie dane użytkowników, w tym dane osobowe oraz informacje\linebreak o celach i zadaniach, muszą być przechowywane i przetwarzane zgodnie z najlepszymi praktykami w zakresie bezpieczeństwa i ochrony danych.
       \end{itemize}
    
    \item {\bf Elastyczność modelu:}
        \begin{itemize}
            \item[*] Aplikacja powinna być elastyczna i pozwalać na łatwe dodawanie nowych modeli LLM oraz aktualizacje istniejących.
       \end{itemize}
    
    \item {\bf Użycie technologii chmurowych:}
        \begin{itemize}
            \item[*] Cała infrastruktura aplikacji, w tym mikroserwisy, bazy danych oraz usługi AI, zostanie wdrożona w chmurze Azure, co zapewni wysoką dostępność, niezawodność oraz łatwość zarządzania.
       \end{itemize}
\end{enumerate}

\subsection{Podstawa teoretyczna}
\begin{enumerate}
    
    \item {\bf Model językowy} - Model językowy w dziedzinie informatyki i sztucznej inteligencji to system komputerowy zaprojektowany do zrozumienia, interpretowania i generowania ludzkiego języka naturalnego. Opiera się on na algorytmach uczenia maszynowego, głównie uczenia głębokiego, które uczą się struktury, semantyki i kontekstu języka przez analizę i przetwarzanie ogromnych zbiorów tekstów.

    Takie modele składają się z wielowarstwowych sieci neuronowych, z których każda warstwa przetwarza różne aspekty języka, od rozpoznawania słów po interpretację znaczeń. Centralnym elementem jest algorytm "transformer", który efektywnie przetwarza długie sekwencje tekstu, zachowując kontekst i znaczenie.
    
    Modele językowe są trenowane na dużych zbiorach tekstowych, zawierających różnorodne formy języka. Proces treningu polega na dostosowywaniu parametrów sieci neuronowej, aby jak najlepiej odwzorować naturalne użycie języka. W wyniku tego treningu, modele te są zdolne do tworzenia nowych, koherentnych wypowiedzi, reagowania na zapytania i analizy języka na wysokim poziomie.
    \\
    \item {\bf Model GPT} - Modele GPT (Generative Pre-trained Transformer) to rodzaj zaawansowanych modeli językowych opracowanych przez firmę OpenAI wykorzystujących architekturę "transformer" w dziedzinie sztucznej inteligencji. Zostały one zaprojektowane do generowania tekstu, interpretacji języka naturalnego oraz wykonywania różnorodnych zadań związanych z przetwarzaniem języka. Ich główną cechą jest zdolność do generowania spójnego i kontekstualnie odpowiedniego tekstu na podstawie dostarczonych informacji wejściowych.

    GPT opiera się na technice uczenia głębokiego, gdzie modele są trenowane na ogromnych zbiorach tekstowych w celu nauki struktury języka, jego semantyki oraz różnorodnych kontekstów. Model GPT, wykorzystując architekturę transformer, skutecznie przetwarza i analizuje długie sekwencje tekstu, co pozwala na zachowanie złożonego kontekstu i generowanie koherentnych odpowiedzi.
    
    Kluczowym aspektem modeli GPT jest ich pre-trening, czyli wstępne szkolenie na szerokiej gamie danych tekstowych. Dzięki temu modele te rozwijają ogólną zdolność do rozumienia i generowania języka, którą następnie można dostosować do konkretnych zastosowań (tzw. fine-tuning).
    
    Modele GPT są wykorzystywane w różnych aplikacjach, od automatycznego generowania tekstu, przez tworzenie odpowiedzi w systemach dialogowych, po zaawansowane analizy językowe. Ich zdolność do generowania naturalnego, spójnego i kontekstowo odpowiedniego języka sprawia, że znajdują one zastosowanie w wielu dziedzinach np. rozrywce, edukacji oraz biznesie.
    \\
     
 \end{enumerate}
\subsection{Analiza rynku oraz podobnych rozwiązań}

\subsubsection{Rys historyczny}
Początki samorozwoju online sięgają wczesnych lat 2000, kiedy to pojawiły się pierwsze serwisy oferujące kursy online, takie jak Coursera i Udemy. Te platformy umożliwiały dostęp do materiałów edukacyjnych z różnych dziedzin, co zapoczątkowało erę zdalnej edukacji i samodzielnego uczenia się. W środkowych latach 2010 rozwinęły się aplikacje mobilne do śledzenia nawyków i celów, takie jak Habitica i Strides, które pomagały użytkownikom w utrzymywaniu codziennych nawyków poprzez mechanizmy grywalizacji\linebreak i śledzenia postępów.
Pod koniec lat 2010 rozwój sztucznej inteligencji (AI) i uczenia maszynowego (ML) przyczynił się do powstania aplikacji, które wykorzystują AI do personalizacji doświadczeń użytkowników. Przykładem takiej aplikacji jest Duolingo, które dostosowuje poziom trudności lekcji do postępów użytkownika. W latach 2020 i później pojawiły się aplikacje, takie jak Fabulous czy Remente, integrujące techniki samorozwoju z AI, oferując spersonalizowane plany i zadania. Również aplikacje coachingu personalnego, jak BetterUp, zaczęły wykorzystywać AI do personalizacji sesji coachingu, co zwiększyło ich skuteczność.

\subsubsection{Przegląd Istniejących lub Podobnych Rozwiązań}
Jednym z popularnych rozwiązań jest "Habitica", aplikacja do śledzenia nawyków w formie gry RPG. Użytkownicy zdobywają punkty i nagrody za wykonywanie zadań, co motywuje ich do utrzymania regularności. "Habitica" jest chwalona za motywację poprzez grywalizację oraz społeczność użytkowników, jednak brakuje jej zaawansowanej personalizacji zadań przy użyciu AI.
Innym przykładem jest "Fabulous", aplikacja koncentrująca się na tworzeniu zdrowych nawyków poprzez prowadzenie użytkownika przez codzienne rutyny. "Fabulous" oferuje świetny interfejs użytkownika oraz podejście naukowe do formowania nawyków, ale personalizacja jest ograniczona do ogólnych profili użytkowników.
"Remente" to aplikacja do zarządzania celami i samorozwoju z elementami coachingu. Posiada bogate zasoby edukacyjne i narzędzia do planowania celów, ale brakuje jej personalizacji opartej na zaawansowanych algorytmach AI. "BetterUp" natomiast oferuje sesje coachingu personalnego wspierane przez AI, co pozwala na personalizację sesji. Jednakże, jest to rozwiązanie bardziej ukierunkowane na korporacje i może być kosztowne.

\begin{figure}[H]
    \centering
    \includegraphics[width=1\linewidth]{Obrazy/habitcaSignIn.png}
    \caption{Strona główna portalu "Habitca"}
    \label{fig:enter-label}
\end{figure}

\subsubsection{Analiza rynku}
Analiza rynku pokazuje, że istnieje rosnące zainteresowanie poprawianiem zdrowia psychicznego i fizycznego. Również można zauważyć trend gdzie występuje personalizacja doświadczeń użytkowników, wynikająca z integracjii sztucznej inteligencji w aplikacjach użytku codziennego. Aplikacje konkurencyjne obejmują tworzenie planu samorozwoju i coachingu personalnego, posiadających różne stopnie personalizacji. Potencjalnymi klientami są osoby szukające narzędzi do zarządzania swoimi celami i nawykami, profesjonalni coachowie szukający wsparcia narzędziowego oraz firmy inwestujące\linebreak w rozwój osobisty swoich pracowników.
To wszystko sprawia, że aplikacja ma potencjał na zrewolucjonizowanie rynku narzędzi do samorozwoju, oferując użytkownikom ciekawą alternatywę do istinejących już narzędzi.

\subsection{Prompt engineering}

\subsubsection{Opis modeli językowych}

\begin{enumerate}
\item {\bf ChatGPT} - to specjalistyczna wersja modelu językowego opracowana przez firmę OpenAI, zaprojektowana głównie z myślą do prowadzenia konwersacji w formie tekstowej. Jest to aplikacja modelu GPT skoncentrowana na interakcjach dialogowych, zdolna do generowania naturalnie brzmiących, spójnych i kontekstualnie adekwatnych odpowiedzi w czasie rzeczywistym.

Podstawą działania ChatGPT jest zaawansowany model językowy oparty na architekturze transformer, który został wytrenowany na ogromnych zbiorach danych tekstowych, w tym na dialogach i rozmowach. Dzięki temu ChatGPT wykazuje zdolność do zrozumienia zapytań w kontekście konwersacji i generowania płynnych, spójnych odpowiedzi.
    
ChatGPT wyróżnia się zdolnością do utrzymania spójnego kontekstu rozmowy, co pozwala na prowadzenie dłuższych interakcji, które wydają się naturalne i są bardziej angażujące dla użytkownika. Może on odpowiadać na pytania, prowadzić dyskusje na różne tematy, oferować pomoc lub informacje, a także angażować się w bardziej twórcze zadania, takie jak pisanie opowiadań czy wierszy.
    
Model ten jest często wykorzystywany w aplikacjach do obsługi klienta, asystentach cyfrowych, edukacji, a także jako narzędzie do interakcji i angażowania użytkowników na platformach internetowych. Zdolność ChatGPT do naturalnej interakcji językowej sprawia, że znajduje on zastosowanie w różnorodnych środowiskach, gdzie istotna jest zdolność do prowadzenia płynnej, ludzko brzmiącej konwersacji.
\\
\item {\bf LLAMA} - LLAMA (Lifelong Language Model Agent) to model językowy opracowany przez firmę Meta, zaprojektowany został do wydajnej pracy z mniejszą ilością danych niż jego konkurenci. Wykorzystuje on technikę zwaną retreningiem, dzięki której jest w stanie dostosować się i uczyć na podstawie nowych informacji przez cały okres swojego działania, co znacznie poprawia jego skuteczność w zadaniach NLP (Natural Language Processing). LLAMA jest także zoptymalizowanym modelem językowym pod kątem wielozadaniowości, dzięki czemu sprawnie radzi sobie z różnorodnymi zadaniami językowymi, zapewniając przy tym efektywność\linebreak w użyciu zasobów obliczeniowych.
\\
\item {\bf Zephyr Stable} - Zephyr Stable LLM to narzędzie do przetwarzania języka naturalnego, które bazuje na modelach uczenia maszynowego. Jest skoncentrowane na stabilności i niezawodności w czasie długotrwałego działania. Jego architektura jest zaprojektowana tak, aby zapewniać równowagę między dokładnością odpowiedzi a zachowaniem spójności i adekwatności w trakcie interakcji z użytkownikiem. Model ten jest szczególnie przydatny w aplikacjach, które wymagają trwałej i efektywnej komunikacji maszyna-człowiek, jak chatboty czy asystenci głosowi, gdzie niezmienna jakość i precyzja są kluczowe.
\\

\end{enumerate}

\subsubsection{Analiza przypdaków użycia modeli językowych}

Rozwój modeli językowych, szczególnie za sprawą zaawansowanych technologii opartych na sztucznej inteligencji, wprowadził nowe możliwości\linebreak w dziedzinie przetwarzania języka naturalnego. Jednym z kluczowych obszarów wykorzystania tych modeli jest prompt engineering, czyli kształtowanie i dostosowywanie zapytań (promptów) w celu uzyskania pożądanych odpowiedzi od modeli językowych. Niniejszy rozdział skupia się na analizie konkretnych przypadków użycia modeli językowych w kontekście prompt engineeringu.

Przed przystąpieniem do analizy przypadków użycia istotne jest określenie modeli językowych, które będą poddane ocenie. W ramach niniejszej pracy magisterskiej skupimy się na modelach opartych na architekturze GPT (Generative Pre-trained Transformer), a w szczególności na, GPT-3.5,GPT-4. Wybór tych modeli wynika z ich doskonałej zdolności do zrozumienia kontekstu, elastyczności w generowaniu tekstów oraz szerokiej gamy zastosowań w dziedzinie języka naturalnego.
 
Analiza przypadków użycia rozpocznie się od szczegółowego zrozumienia procesu prompt engineeringu. Proces ten obejmuje identyfikację celu zapytania, dostosowanie struktury promptu, a także optymalizację parametrów modelu w celu uzyskania precyzyjnych i zadowalających wyników. Przeanalizujemy różne strategie prompt engineeringu, w tym zmiany w sformułowaniu pytań, manipulacje długością promptu oraz eksperymenty z parametrami kontekstowymi.

\subsubsection{Projektowanie promptów}

\noindent\textbf{Wprowadzenie}

Projektowanie promptów jest kluczowym aspektem w tworzeniu efektywnych interakcji z modelami językowymi. Precyzyjne i dobrze sformułowane pytania mają decydujący wpływ na jakość generowanych odpowiedzi. W tym rozdziale skoncentrujemy się na procesie projektowania promptów, w tym na strategiach wyboru słów kluczowych, formatowaniu zapytań oraz eksperymentach z różnymi rodzajami promptów.
\\

\noindent\textbf{Analiza celu naszego prompta}

Każdy prompt, musi zostac tak zaprojektowany aby spełniał wymagania techniczne aplikacji.
Aplikacja jest podzielona na wiele etapów gdzie użytkownik otrzymuje specjalnie wygenerowane odpowiedzi w zależności od opcji, które wcześniej wybierze.
\\

\noindent\textbf{Wybór Słów Kluczowych}

Pierwszym etapem projektowania promptów jest staranne dobranie słów kluczowych. Te słowa stanowią istotny element, który kieruje modelem językowym w odpowiednim kierunku. Analiza semantyczna i kontekstualna danego zadania jest kluczowa w identyfikacji słów, które mają kluczowe znaczenie dla uzyskania precyzyjnych odpowiedzi. W tym kontekście eksperymenty z różnymi formułowaniami pytań mogą prowadzić do odkrycia najbardziej efektywnych kombinacji słów kluczowych.
\\

\noindent\textbf{Struktura Promptów}

Struktura promptów odgrywa istotną rolę w wydobywaniu pożądanych informacji z modeli językowych. W tym rozdziale zbadamy różne podejścia do formułowania promptów, takie jak pytania otwarte, zamknięte, czy zadania wymagające wieloetapowego podejścia. Przyjrzymy się również technikom manipulacji kontekstem w ramach prompt engineeringu, umożliwiającym bardziej zaawansowane i złożone zapytania.

\subsubsection{Prompt security}

{\bf Czym jest bezpieczeństwo promptów?}

\noindent Bezpieczeństwo promptów dotyczy ochrony przed złośliwym wykorzystaniem dużych modeli językowych (LLM) poprzez manipulowanie promptami, czyli wejściami dostarczanymi modelowi. Ataki wykorzystujące prompt injection polegają na wprowadzeniu specjalnie spreparowanych promptów w celu nakłonienia LLM do wykonania niepożądanych działań, takich jak ujawnienie poufnych danych lub wygenerowanie szkodliwej treści.
\\

\noindent {\bf Zagrożenia:}

\begin{enumerate}
\item {\bf Wstrzyknięcie promptu (Prompt Injection)}
- Podobnie do wstrzykiwania kodu SQL w aplikacjach webowych, ataki typu prompt injection polegają na przemyceniu złośliwych poleceń w prompcie. Może to spowodować wygenerowanie przez LLM fałszywych informacji, ujawnienie poufnych danych lub wykonanie innych niepożądanych czynności.
\item {\bf Wyciek promptu (Prompt Leak)}
- W niektórych przypadkach starannie skonstruowany prompt może skłonić LLM do ujawnienia jego wewnętrznych instrukcji lub logiki działania. Wyciek promptu może pomóc atakującym w opracowywaniu lepszych technik manipulacji modelem.
\end{enumerate}

{\bf Znaczenie bezpieczeństwa promptów}

\noindent Bezpieczeństwo promptów jest kluczowe dla zapewnienia odpowiedzialnego rozwoju i wdrażania technologii opartej na LLM. Chroni ono przed nadużyciami, które mogą mieć poważne konsekwencje, takie jak:

\begin{enumerate}
\item {\bf Utrata danych poufnych}
- Wstrzyknięcie promptu może zmusić LLM do ujawnienia poufnych informacji, takich jak dane finansowe lub dane osobowe.
\item {\bf Dezinformacja i propaganda}
- Ataki mogą być wykorzystywane do generowania fałszywych wiadomości lub propagandy, która może wpływać na opinię publiczną.
\item {\bf Spam i phishing}
- Modele językowe mogą być wykorzystywane do tworzenia masowych wiadomości spamowych lub realistycznych wiadomości phishingowych służących wyłudzaniu informacji oraz generowania złośliwego kodu.
\end{enumerate}

{\bf Rozwiązania bezpieczeństwa promptów}

\noindent Firmy zajmujące się bezpieczeństwem cybernetycznym opracowują narzędzia i techniki wykrywania i zapobiegania atakom na prompt security. Niektóre\linebreak z rozwiązań obejmują:

\begin{enumerate}
\item {\bf Analizę i monitorowanie promptów} - Wykrywanie podejrzanych wzorców w promptach wprowadzanych do LLM.
\item {\bf Weryfikację danych wyjściowych} - Sprawdzanie, czy wygenerowane przez LLM dane są zgodne z oczekiwaniami i nie zawierają szkodliwych informacji.
\item {\bf Szkolenie LLM w zakresie bezpieczeństwa} - Opracowywanie modeli odpornych na manipulacje poprzez odpowiednie ich szkolenie i zwracanie uwagi na kluczowe parametry.
\end{enumerate}

\noindent{\bf Wnioski}

\noindent Bezpieczeństwo promptów to ważny, ale często pomijany aspekt rozwoju i wdrażania generatywnej sztucznej inteligencji. Wraz z ciągłym rozwojem technologii sztucznej inteligencji, konieczne jest opracowanie solidnych mechanizmów bezpieczeństwa w celu ochrony przed potencjalnymi zagrożeniami. Rozwiązania te zapewnią, że technologia ta będzie wykorzystywana\linebreak w sposób odpowiedzialny i przyniesie korzyści społeczeństwu.

\subsubsection{Fine-tuning}
Jest to modyfikowanie istniejących modeli językowych w celu dostosowania ich do konkretnego zadania lub zbioru danych, odgrywa kluczową rolę w dziedzinie uczenia maszynowego i przetwarzania języka naturalnego. Proces ten polega na dalszym trenowaniu modeli na specyficznych danych lub zadaniach, co pozwala na poprawę ich wydajności i skuteczności w konkretnych zastosowaniach. Fine-tuning modeli LLM może być stosowany do różnorodnych zadań, takich jak tłumaczenie maszynowe, generowanie tekstu, analiza kodu czy wykrywanie fraz kluczowych. W ten sposób możliwe jest dostosowanie ogólnych modeli językowych do specyficznych potrzeb użytkowników i zastosowań, co przyczynia się do poprawy jakości rezultatów oraz dostosowania modeli do konkretnego kontekstu biznesowego lub naukowego.

\subsubsection{Halucynacje sztucznej inteligencji}
Halucynacje sztucznej inteligencji to zjawisko, w którym modele językowe generują odpowiedzi, które nie mają podstaw w rzeczywistych danych, na których zostały przeszkolone.

Halucynacje to potencjalnie nieprawidłowe, niezamierzone i nierealistyczne wyniki generowane przez modele językowe, wynikające z ich niezdolności do zrozumienia istotnych informacji opartych na danych treningowych. Mogą one przybierać formę odpowiedzi, które brzmią przekonująco, ale nie mają pokrycia w faktach.

Głównymi przyczynami halucynacji mogą być ograniczone dane treningowe. Jeśli zestaw zbiorów danych jest niewystarczający lub brakuje różnorodności, model może mieć trudności z uchwyceniem złożoności języka, co prowadzi do tak zwanych halucynacji.

Kolejnym ważnym aspektem mogą być, błędy w danych treningowych, jeśli zawierają luki lub błędne informacje modele mogą włączyć\linebreak i wzmocnić te uprzedzenia, utrwalające fałszywe informacje.

Również dużą rolę w jakości informacji odgrywa szum danych wejściowych. Niekompletne lub zaszumione dane wejściowe utrudniają modelom dokładne przewidywanie, co prowadzi do zwrócenia błędnych odpowiedzi przez model językowy.

Halucynacje mogą prowadzić do generowania fałszywych informacji, takich jak sfabrykowane fakty, nieprawdziwe twierdzenia czy zmyślone sytuacje. Stanowi to poważne zagrożenie dla wiarygodności i dokładności informacji dostarczanych przez modele AI, szczególnie w dziedzinach wymagających wieloetapowego rozumowania.

Badania wykazały, że niektóre popularne chatboty, takie jak ChatGPT, Bard i Bing, mogą halucynować nawet w co czwartej odpowiedzi. Dlatego kluczowe jest świadome korzystanie z tych narzędzi i weryfikowanie uzyskanych informacji.

Firmy takie jak OpenAI podejmują wysiłki, aby zminimalizować halucynacje, stosując techniki takie jak "nadzór procesu" - monitorowanie procesu generowania odpowiedzi w celu wykrycia i skorygowania potencjalnych halucynacji.

\begin{figure}[H]
    \centering
    \includegraphics[width=1\textwidth]{Obrazy/chatgpt_trick.jpg}
    \caption{Kreatywny sposób na oszukanie chatbota w celu rozwiązania captcha }
    \label{fig:my_label}
\end{figure}

\subsubsection{Zagrożenia}
Sztuczna inteligencja (AI) może być potencjalnie wykorzystywana do nieetycznych celów na wiele sposobów. 

Jeśli dane treningowe dla modeli AI zawierają uprzedzenia lub wzorce dyskryminacji, algorytmy mogą je utrwalać i powielać na dużą skalę. Może to prowadzić do niesprawiedliwych decyzji i nierównego traktowania niektórych grup społecznych. Zaawansowane systemy AI mogą być wykorzystywane do masowej inwigilacji, śledzenia i gromadzenia danych osobowych bez zgody i wiedzy osób, naruszając ich prawo do własności intelektualnej.

Modele językowe mogą być użyte do tworzenia fałszywych treści, takich jak deepfake' w postaci fałszywych nagrań, zdjęć przedstawiających wydarzenia nieprawdziwe lub wiadomości.

Nieodpowiednio wykorzystane zdolności sztucznej inteligencji mogą być wykorzystywane przez hakerów do tworzenia zaawansowanych wirusów, botnetów i innych form szkodliwego oprogramowania, które są trudniejsze do wykrycia i zwalczania.

\subsubsection{Large Language Models}
Duże modele językowe (LLM) to zaawansowane algorytmy sztucznej inteligencji, które wykorzystują techniki głębokiego uczenia się i obszerne zbiory danych do generowania, podsumowywania i przewidywania nowych treści w języku naturalnym. Modele te, opierają się głównie na transformatorach, są zaprojektowane tak, aby rozumieć relacje między słowami\linebreak i frazami, umożliwiając im równoległe przetwarzanie całych sekwencji tekstu. Szkolenie odbywa się na ogromnych ilościach danych, zazwyczaj z miliardami parametrów, co pozwala im na dostarczanie dokładnych i szybkich odpowiedzi. Modele językowe wiążą się również z wyzwaniami, takimi jak wysokie koszty rozwoju i operacyjne, potencjalna stronniczość danych szkoleniowych, ryzyko halucynacji (dostarczanie niedokładnych odpowiedzi) oraz złożoność ze względu na dużą liczbę parametrów.

\subsubsection{Ranking Modeli}

\begin{figure}[H]
    \centering
    \includegraphics[width=1\textwidth]{Obrazy/llms_benchmark.png}
    \caption{Benchmark modeli LLM}
    \label{fig:my_label}
\end{figure}

Ranking modeli został przeprowadzony na środowisku lokalnym\linebreak z kartą graficzną NVIDIA GeForce GTX 1060. Na podanej wyżej tabeli zaznaczono nazwy modeli kolorem zielonym, które są modelami open source i można je skonfigurować do pracy na środowisku lokalnym. W rankingu uwzględniono liczbę parametrów danego modelu wyrażnoną w miliardach. Następnie czas odpowiedzi na ten sam prompt dotyczący prośby o wygenerowanie planu treningowego dla użytkownika aplikacji. Dołączone zostały również koszty jakie trzeba ponieść aby dany model językowy mógł funkcjonować, pomijając koszty winikające z opłat energii elektrycznej i innych czynników zewnętrznych. Szybko można zauważyć dość oczywistą zależność, że płatne modele Chat GPT odpowiadają szybciej niż te na lokalnej maszynie. Dedykowane środowiska oraz konfiguracje zapewnione przez firmę OpenAI powodują, że model językowy odpowiada w sposób niemal natychmiastowy, nie trzeba oczekiwać na kolejne generowane słowa długo. Czas jest jednym z kluczowych aspektów podczas budowania aplikacji, użytkownik nie powinien być zmuszony do długiego oczekiwania na efekt końcowy. Żeby modele lokalne nie odbiegały prędkością odpowiedzi swojemu płatnemu odpowiednikowi, należałoby zainwestować w lepszą kartę graficzną bądź skorzystać z dedykowanego chmurowego rozwiązania z profesjonalnym chipem, zoptymalizowanym pod sztuczą inteligencję. Niestety budżet naszego projektu nie był na tyle duży, aby podjąć się takiego przedsięwzięcia.
\\

\noindent Modele zostały ocenione w 6 stopniowej skali oceniania w kategoriach:
\begin{enumerate}
    \item zrozumiałość zwróconego tekstu
    \item poprawność formatu odpowiedzi
    \item ocena odpowiedzi pod względem umiejętności dopasowania generowanych danych dla użytkownika końcowego
\end{enumerate}

\paragraph{} Tutaj modele OpenAI ponownie dominują nad swoją konkurencją. Nie tylko lepiej dostosowywują się do zadanego prompta, ale też łatwiej dodać ich efekty operacji do finalnej aplikacji.
Plany oraz zadania były znacznie wyższej jakości niż darmowych odpowiedników. Przyglądając się liczbie parametrów można założyć tezę, że model firmy Meta z  ok. 8B parametrów poradzi sobie lepiej niż ChatGPT, jednak znany chatbot poradził sobie lepiej z generowaniem treści.

\subsubsection{Etyka}
Wraz z bardzo szybkim rozwojem sztucznej inteligencji, pojawia się wiele dylematów natury etycznej związanych zarówno z prawami autorskimi trenowanych danych oraz faktycznych rezultatów stworzonych przez AI. Istnieje ryzyko, że modele mogą przekazywać błędne informacje, szerzyć dezinformację, lub być źródłem treści szkodliwych często nielegalnych. Dlatego ważne jest, aby organizacje i twórcy tych modeli dbali o uczciwość, transparentność, oraz brali odpowiedzialność za generowane treści.

\subsection{Platformy chmurowe}
Platformy chmurowe to zaawansowane systemy, które umożliwiają firmom i organizacjom dostęp do zasobów obliczeniowych przez Internet, bez konieczności posiadania i zarządzania własną infrastrukturą IT.

Platforma chmurowa to komponenty składające się z systemów operacyjnych, serwerów w centrum danych skonfigurowanych pod personalne potrzeby klientów. Umożliwiają one organizacjom wynajmowanie dostępu do zasobów obliczeniowych, takich jak serwery, bazy danych, magazyny danych, analityk, sieci wirtualnych. Model biznesowy dostawców usług chmurowych opiera się na zasadzie "pay as you go" (z .ang) płać za te zasoby, które zużyjesz.
\\

\noindent{\bf Usługi chmurowe możemy podzielić na trzy kluczowe rodzaje:}

\begin{enumerate}
    \item {\bf Chmura Publiczna:} Usługi świadczone przez zewnętrznych dostawców, dostępne dla wielu klientów przez Internet. Przykłady to Amazon Web Services (AWS), Google Cloud Platform, Microsoft Azure, Alibaba Cloud i IBM Cloud.
    \item {\bf  Chmura Prywatna:} Dedykowana dla jednej organizacji, może być zarządzana wewnętrznie lub przez zewnętrznego dostawcę. Oferuje większą kontrolę nad zasobami i bezpieczeństwem.
    \item {\bf Chmura Hybrydowa:} Chmura Hybrydowa: Kombinacja chmury publicznej i prywatnej, umożliwiająca przenoszenie danych i aplikacji między nimi, co zapewnia większą elastyczność i optymalizację infrastruktury.
\end{enumerate} 

\noindent{\bf Korzyści z Używania Platform Chmurowych:}
\begin{enumerate}
    \item {\bf Elastyczność:}  Możliwość szybkiego skalowania zasobów w górę lub w dół w zależności od potrzeb biznesowych, co pozwala uniknąć nadmiernego lub niedostatecznego przydziału zasobów obliczeniowych.
    \item {\bf Redukcja Kosztów:}  Eliminacja kosztów kapitałowych związanych z budową i utrzymaniem własnych centrów danych oraz płatność tylko za faktycznie używane zasoby.
    \item {\bf Wydajność:} Dostęp do dużej mocy obliczeniowej i magazynowej na żądanie, co pozwala unikać wąskich gardeł i zapewnia lepszą wydajność aplikacji.
    \item {\bf Szybkość Wdrożenia:} Możliwość szybkiego wdrażania technologii na całym świecie, co skraca czas wprowadzenia produktów na rynek.
    \item {\bf Zwiększona Produktywność:} Zespoły IT są zwolnione z zarządzania, utrzymania i aktualizacji sprzętu i oprogramowania na miejscu, co pozwala im skupić się na bardziej strategicznych zadaniach.
    \item {\bf Bezpieczeństwo:} Dostawcy chmurowi inwestują znaczne środki w technologie zabezpieczające, co często zapewnia wyższy poziom bezpieczeństwa niż w przypadku własnych centrów danych.
    \item {\bf Niezawodność:} Platformy chmurowe są bardziej odporne dzięki rozproszonej infrastrukturze, co zapewnia szybsze odzyskiwanie danych po awariach systemów.
    
\end{enumerate}
Platformy chmurowe odgrywają kluczową rolę w nowoczesnych strategiach IT, umożliwiając firmom szybkie i efektywne skalowanie swoich operacji oraz wprowadzanie innowacji.

\subsubsection{Opis platform}
Platformy chmurowe to zintegrowane zestawy technologii umożliwiające użytkownikom zdalne korzystanie z szerokiej gamy zasobów komputerowych przez Internet. Te cyfrowe ekosystemy oferują skalowalne rozwiązania IT, takie jak serwery, pamięć, bazy danych oraz oprogramowanie, wszystko dostępne jako usługa. Główne kategorie tych usług to: Infrastructure as a Service (IaaS), Platform as a Service (PaaS) oraz Software as a Service (SaaS).

Korzystanie z platform chmurowych przynosi wiele korzyści. Elastyczność i skalowalność pozwalają na szybkie dostosowywanie zasobów do aktualnych potrzeb, bez konieczności inwestycji w drogi sprzęt i infrastrukturę. Oszczędności kosztów wynikają z modelu opłat "pay as you go", co oznacza, że płaci się tylko za te zasoby, które są faktycznie wykorzystywane. Bezpieczeństwo danych jest również kluczowym aspektem, z zaawansowanymi rozwiązaniami chroniącymi przed utratą danych i cyberatakami.

\subsubsection{Wybór - Plaforma Microsoft Azure}
Platfroma Azure została wybrana do naszego projektu ze względu na to,że nasz zespół miał już doświadczenie zarówno prywatne jak i komercyjne w tej technologi. Kolejnym atutem rozwiązania firmy z Redmond, jest bogata oferta serwisów oraz technologii potrzebnych do zbudowania do aplikacji opartej o architekturę mikroserwisów.
W tym kontekście, Azure okazuje się być idealną platformą do rozwijania mikroserwisów dzięki usługom takim jak Azure Kubernetes Service, który upraszcza zarządzanie kontenerami, oraz Azure Container Instances. Platforma oferuje również integracje z narzędziami deweloperskimi oraz CI/CD.

\subsection{Wymagania funkcjonalne}

\subsubsection{Opis funkcjonalności systemu}

\noindent Aplikacja ma posiadać następujące funkcjonalności systemu:
\begin{enumerate}
    \item[*] {\bf Rejestracja użytkownika} - polega na utworzeniu konta użytkownika poprzez podanie adresu e-mail, nazwy i hasła.
    \item[*] {\bf Logowanie użytkownika} - umożliwia zalogowanie się do aplikacji za pomocą adresu e-mail i hasła.
    \item[*] {\bf Tworzenie celów} - pozwala użytkownikowi na definiowanie nowych celów do osiągnięcia.
    \item[*] {\bf Generowanie planów} - wykorzystuje modele LLM do generowania planów działania dla zdefiniowanych celów.
    \item[*] {\bf Wyświetlanie listy zadań} - prezentuje użytkownikowi listę zadań do wykonania w celu osiągnięcia zamierzonego celu.
    \item[*] {\bf Zarządzanie zadaniami} - umożliwia użytkownikowi oznaczanie zadań jako ukończone lub nieukończone.
    \item[*] {\bf Przyznawanie osiągnięć} - moduł, który przyznaje użytkownikom odznaki za realizację określonej liczby celów i zadań, motywując ich do dalszego działania. Użytkownicy mogą zdobywać różne odznaki, które są widoczne na ich profilach.
    \item[*] {\bf Integracja z modelami LLM} - zapewnia komunikację z wybranymi modelami LLM w celu generowania planów działania.
    \item[*] {\bf Zabezpieczone strony} - chroni dostęp do określonych stron aplikacji, wymagając uprzedniego zalogowania.
\end{enumerate}

\subsubsection{Diagram przypadków użycia}

\begin{figure}[H]
    \centering
    \includegraphics[width=0.9\textwidth]{Obrazy/diagrams/use_case_diagram.png}
    \caption{Diagram przypadków użycia}
    \label{fig:my_label}
\end{figure}

\subsubsection{Scenariusze przypadków użycia}

{\noindent \bf{\small 1. Rejestracja użytkownika\par}}
\vspace{0.5cm}
{\noindent \bf Kontekst użycia: } Rejestracja użytkownika w systemie\\
{\bf Poziom: } Cel użytkownika\\
{\bf Aktor główny: } Użytkownik\\
{\bf Warunek początkowy: } W aplikacji (bazie danych) użytkownik nie posiada konta\\
{\bf Gwarancja powodzenia: } W aplikacji (bazie danych) został zarejestrowany użytkownik\\
{\bf Wyzwalacz: } Użytkownik\\
{\bf Główny scenariusz powodzenia: }
\begin{center}
    \begin{enumerate}
        \item Użytkownik (aktor) uruchamia przypadek użycia
        \item Aktor wypełnia formularz rejestracyjny i klika przycisk rejestracji
        \item System zapisuje dane użytkownika i tworzy nowe konto
        \item Wyświetla się strona z panelem użytkownika
        \item Aplikacja kończy przypadek użycia
    \end{enumerate}
\end{center}
{\noindent \bf Rozszerzenia: }
\begin{center}
    \begin{description}
        \item{2a.} Podany adres e-mail jest już zarejestrowany, rejestracja nie powiodła się
    \end{description}
\end{center}

\noindent\rule{14cm}{0.1pt} % długość i grubość linii

{\noindent \bf{\small 2. Logowanie użytkownika\par}}
\vspace{0.5cm}
{\noindent \bf Kontekst użycia: } Logowanie użytkownika do systemu\\
{\bf Poziom: } Cel użytkownika\\
{\bf Aktor główny: } Użytkownik\\
{\bf Warunek początkowy: } W aplikacji (bazie danych) użytkownik posiada konto\\
{\bf Gwarancja powodzenia: } W aplikacji użytkownik został zalogowany\\
{\bf Wyzwalacz: } Użytkownik\\
{\bf Główny scenariusz powodzenia: }
\begin{center}
    \begin{enumerate}
        \item Użytkownik (aktor) uruchamia przypadek użycia
        \item Aktor wypełnia formularz logowania i klika przycisk logowania
        \item System weryfikuje dane i loguje użytkownika
        \item Wyświetla się strona z panelem użytkownika
        \item Aplikacja kończy przypadek użycia
    \end{enumerate}
\end{center}
{\noindent \bf Rozszerzenia: }
\begin{center}
    \begin{description}
        \item{2a.} Podany adres e-mail lub hasło jest nieprawidłowe, logowanie nie powiodło się
    \end{description}
\end{center}

\noindent\rule{14cm}{0.1pt} % długość i grubość linii

\clearpage

{\noindent \bf{\small 3. Dodaj cel\par}}
\vspace{0.5cm}
{\noindent \bf Kontekst użycia: } Dodawanie nowego celu przez użytkownika\\
{\bf Poziom: } Cel użytkownika\\
{\bf Aktor główny: } Użytkownik\\
{\bf Warunek początkowy: } Użytkownik jest zalogowany w systemie\\
{\bf Gwarancja powodzenia: } Nowy cel został zapisany w systemie\\
{\bf Wyzwalacz: } Użytkownik\\
{\bf Główny scenariusz powodzenia: }
\begin{center}
    \begin{enumerate}
        \item Użytkownik (aktor) uruchamia przypadek użycia
        \item Aktor wypełnia formularz dodawania celu i klika przycisk zapisu
        \item System zapisuje nowy cel
        \item Wyświetla się widok szczegółowy celu z nowo dodanymi zadaniami
        \item Aplikacja kończy przypadek użycia
    \end{enumerate}
\end{center}
{\noindent \bf Rozszerzenia: }
\begin{center}
    \begin{description}
        \item{2a.} Formularz zawiera nieprawidłowe dane, cel nie został zapisany
    \end{description}
\end{center}

\noindent\rule{14cm}{0.1pt} % długość i grubość linii

{\noindent \bf{\small 4. Wyświetl stronę startową\par}}
\vspace{0.5cm}
{\noindent \bf Kontekst użycia: } Wyświetlanie strony startowej aplikacji\\
{\bf Poziom: } Cel użytkownika\\
{\bf Aktor główny: } Użytkownik\\
{\bf Warunek początkowy: } Użytkownik jest zalogowany w systemie\\
{\bf Gwarancja powodzenia: } Strona startowa została poprawnie wyświetlona\\
{\bf Wyzwalacz: } Użytkownik\\
{\bf Główny scenariusz powodzenia: }
\begin{center}
    \begin{enumerate}
        \item Użytkownik (aktor) uruchamia przypadek użycia
        \item System ładuje i wyświetla stronę startową
        \item Aplikacja kończy przypadek użycia
    \end{enumerate}
\end{center}

\noindent\rule{14cm}{0.1pt} % długość i grubość linii

\clearpage

{\noindent \bf{\small 5. Wyświetl cele\par}}
\vspace{0.5cm}
{\noindent \bf Kontekst użycia: } Wyświetlanie listy celów użytkownika\\
{\bf Poziom: } Cel użytkownika\\
{\bf Aktor główny: } Użytkownik\\
{\bf Warunek początkowy: } Użytkownik jest zalogowany w systemie\\
{\bf Gwarancja powodzenia: } Lista celów została poprawnie wyświetlona\\
{\bf Wyzwalacz: } Użytkownik\\
{\bf Główny scenariusz powodzenia: }
\begin{center}
    \begin{enumerate}
        \item Użytkownik (aktor) uruchamia przypadek użycia
        \item System ładuje i wyświetla listę celów użytkownika
        \item Aplikacja kończy przypadek użycia
    \end{enumerate}
\end{center}

\noindent\rule{14cm}{0.1pt} % długość i grubość linii

{\noindent \bf{\small 6. Wyświetl szczegóły celu\par}}
\vspace{0.5cm}
{\noindent \bf Kontekst użycia: } Wyświetlanie szczegółów wybranego celu\\
{\bf Poziom: } Cel użytkownika\\
{\bf Aktor główny: } Użytkownik\\
{\bf Warunek początkowy: } Użytkownik jest zalogowany w systemie, posiada zapisane cele\\
{\bf Gwarancja powodzenia: } Szczegóły celu zostały poprawnie wyświetlone\\
{\bf Wyzwalacz: } Użytkownik\\
{\bf Główny scenariusz powodzenia: }
\begin{center}
    \begin{enumerate}
        \item Użytkownik (aktor) uruchamia przypadek użycia
        \item System ładuje i wyświetla szczegóły wybranego celu
        \item Aplikacja kończy przypadek użycia
    \end{enumerate}
\end{center}

\noindent\rule{14cm}{0.1pt} % długość i grubość linii

\clearpage

{\noindent \bf{\small 7. Wyświetl wszystkie zadania\par}}
\vspace{0.5cm}
{\noindent \bf Kontekst użycia: } Wyświetlanie listy wszystkich zadań\\
{\bf Poziom: } Cel użytkownika\\
{\bf Aktor główny: } Użytkownik\\
{\bf Warunek początkowy: } Użytkownik jest zalogowany w systemie\\
{\bf Gwarancja powodzenia: } Lista zadań została poprawnie wyświetlona\\
{\bf Wyzwalacz: } Użytkownik\\
{\bf Główny scenariusz powodzenia: }
\begin{center}
    \begin{enumerate}
        \item Użytkownik (aktor) uruchamia przypadek użycia
        \item System ładuje i wyświetla listę wszystkich zadań
        \item Aplikacja kończy przypadek użycia
    \end{enumerate}
\end{center}

\noindent\rule{14cm}{0.1pt} % długość i grubość linii

{\noindent \bf{\small 8. Wyświetl szczegóły zadania\par}}
\vspace{0.5cm}
{\noindent \bf Kontekst użycia: } Wyświetlanie szczegółów wybranego zadania\\
{\bf Poziom: } Cel użytkownika\\
{\bf Aktor główny: } Użytkownik\\
{\bf Warunek początkowy: } Użytkownik jest zalogowany w systemie, posiada zapisane zadania\\
{\bf Gwarancja powodzenia: } Szczegóły zadania zostały poprawnie wyświetlone\\
{\bf Wyzwalacz: } Użytkownik\\
{\bf Główny scenariusz powodzenia: }
\begin{center}
    \begin{enumerate}
        \item Użytkownik (aktor) uruchamia przypadek użycia
        \item System ładuje i wyświetla szczegóły wybranego zadania
        \item Aplikacja kończy przypadek użycia
    \end{enumerate}
\end{center}

\noindent\rule{14cm}{0.1pt} % długość i grubość linii

\clearpage

{\noindent \bf{\small 9. Edytuj szczegóły konta\par}}
\vspace{0.5cm}
{\noindent \bf Kontekst użycia: } Edytowanie szczegółów konta użytkownika\\
{\bf Poziom: } Cel użytkownika\\
{\bf Aktor główny: } Użytkownik\\
{\bf Warunek początkowy: } Użytkownik jest zalogowany w systemie\\
{\bf Gwarancja powodzenia: } Szczegóły konta zostały poprawnie zaktualizowane\\
{\bf Wyzwalacz: } Użytkownik\\
{\bf Główny scenariusz powodzenia: }
\begin{enumerate}
    \item Użytkownik (aktor) uruchamia przypadek użycia
    \item System ładuje formularz edycji szczegółów konta
    \item Użytkownik wypełnia formularz i zapisuje zmiany
    \item System zapisuje zaktualizowane dane użytkownika
    \item Aplikacja kończy przypadek użycia
\end{enumerate}
{\noindent \bf Rozszerzenia: }
\begin{description}
    \item[4a.] Formularz zawiera nieprawidłowe dane, edycja nie powiodła się
\end{description}

\subsubsection{Sposób przechowywania danych}
Dane użytkowników są przechowywane w bazie danych PostgreSQL, co zapewnia efektywne zarządzanie dużymi zbiorami danych oraz wysoki poziom bezpieczeństwa. PostgreSQL, jako zaawansowany system zarządzania relacyjnymi bazami danych, oferuje szerokie możliwości skalowania i optymalizacji, co jest kluczowe przy obsłudze danych wrażliwych i osobowych.

\clearpage

\subsubsection{Diagramy}

{\noindent \bf Diagram aktywności dodania celu: }
\begin{figure}[H]
    \centering
    \includegraphics[width=1\textwidth]{Obrazy/diagrams/add_goal_activity_diagram.png}
    \caption{Diagram Aktywności dla przypadku dodanie celu}
    \label{fig:my_label}
\end{figure}

\noindent Powyższy diagram aktywności przedstawia cały proces dodawania celu od momentu rozpoczęcia do zakończenia. Uwzględnia on interakcje użytkownika z systemem, walidację danych, zapis do bazy danych oraz aktualizację interfejsu użytkownika. Jest to pomocne narzędzie do zrozumienia przepływu pracy oraz identyfikacji potencjalnych punktów poprawy w procesie.

\clearpage

\subsection{Wymagania niefunkcjonalne}
\begin{itemize}
    \item[*] W przypadku gdy użytkownik korzysta z komputera stacjonarnego lub urządzenia mobilnego aplikacja powinna działać na: Google Chrome(wersja 95 i wyżej), Firefox lub Opera. 
    \item[*] Aplikacja powinna poprawnie działać na środowisku chmurowym np. Azure. Rekomendowanym systemem operacyjnym jest 64 bitowy system GNU/Linux, ponieważ najlepiej jest on przystosowany do środowiska chmurowego. W przypadku użycia kontenerów zalecane jest utworzenie własnego repozytorium do przechowywania źródeł obrazów np. Azure Conainer Registry. Ddla każdego uruchomionego kontenera należy zapewnić minimum 1 rdzeń procesora oraz 2GB pamięci RAM. Dla optymalizacji działania aplikacji, wszystkie komponenty powinny się znajdować w tej samej lub bardzo do siebie zbliżonej lokalizacji, aby uniknąć zbędnych opóźnień.
    \item[*] Aplikacja uruchomiona na lokalnym środowisku powinna poprawnie działać na komputerze z zainstalowanym system operacyjnym wspierającym konteneryzację Docker oraz wirtualizację np. Ubuntu Linux lub Windows 10/11. Najlepiej używać procesora o architekturze "x86\_64/amd64" i posiadać minmalną ilość pamięci RAM wynoszącej 4GB.
\end{itemize}
\clearpage

\subsection{Opis prototypów}
Prototypy opracowane na etapie planowania całej aplikacji okazały się niezwykle pomocne w ustaleniu funkcjonalności oraz ogólnego zarysu aplikacji. Jednakże, po dokładnej analizie trendów dotyczących UX/UI oraz tematyki aplikacji, konieczne było wykonanie nowego aspektu wizualnego. Zmieniono kolorystykę oraz doprecyzowano wygląd poszczególnych komponentów, aby spełnić wymagania standardów UX/UI oraz zapewnić użytkownikom maksymalny komfort podczas korzystania z aplikacji. Ważnym celem było stworzenie projektu przyjaznego i intuicyjnego, a także spełnienie wymogów dotyczących dostępności. Wszystkie te aspekty zostały uwzględnione podczas projektowania i implementacji aplikacji.

\begin{figure}[H]
    \centering
    \includegraphics[width=1\textwidth]{Obrazy/prototypy/logowanie.png}
    \caption{Prototyp ekranu logowania}
    \label{fig:my_label}
\end{figure}

\begin{figure}[H]
    \centering
    \includegraphics[width=1\textwidth]{Obrazy/prototypy/personalizacja_konta.png}
    \caption{Prototyp ekranu personalizacji konta}
    \label{fig:my_label}
\end{figure}

\begin{figure}[H]
    \centering
    \includegraphics[width=1\textwidth]{Obrazy/prototypy/strona_startowa.png}
    \caption{Prototyp strony startowej}
    \label{fig:my_label}
\end{figure}

\begin{figure}[H]
    \centering
    \includegraphics[width=1\textwidth]{Obrazy/prototypy/panel_zadania.png}
    \caption{Prototyp panelu zadania}
    \label{fig:my_label}
\end{figure}

\begin{figure}[H]
    \centering
    \includegraphics[width=1\textwidth]{Obrazy/prototypy/kalendarz.png}
    \caption{Prototyp kalendarza}
    \label{fig:my_label}
\end{figure}

\begin{figure}[H]
    \centering
    \includegraphics[width=1\textwidth]{Obrazy/prototypy/profil_uzytkownika.png}
    \caption{Prototyp profilu użytkownika}
    \label{fig:my_label}
\end{figure}

\clearpage